%
% File nodalida2015.tex
%
% Contact beata.megyesi@lingfil.uu.se
%
% Based on the instruction file for EACL 2014
% which in turn was based on the instruction files for previous 
% ACL and EACL conferences.

\documentclass[11pt]{article}
\usepackage{nodalida2015}
\usepackage{times}
\usepackage{mathptmx}
\usepackage{fixltx2e}
%\usepackage{txfonts}
\usepackage{url}
\usepackage{latexsym}
\usepackage{cite}
\usepackage{authordate1-4}
\usepackage{multirow}
\special{papersize=210mm,297mm} % to avoid having to use "-t a4" with dvips 
%\setlength\titlebox{6.5cm}  % You can expand the title box if you really have to

\usepackage{color}
\newcommand{\todo}[1]{{\color{cyan}\textbf{[TODO: }#1\textbf{]}}}
\usepackage{tikz}
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) --
  (.25,.15) -- cycle;}
\newcommand{\Mypm}{\mathbin{\tikz [x=1.4ex,y=1.4ex,line width=.1ex] \draw (0.0,0) -- (1.0,0) (0.5,0.08) -- (0.5,0.92) (0.0,0.5) -- (1.0,0.5);}}%

\title{Constraint Grammar as a SAT problem}

\author{Inari Listenmaa \and Koen Claessen \\
 Chalmers University of Technology, Gothenburg, Sweden \\
 {\tt \{inari,koen\}@chalmers.se} }

\date{\today}

\begin{document}
\maketitle

\begin{abstract} 

We represent Constraint Grammar (CG) as a Boolean satisfiability (SAT) problem.
Encoding CG in logic brings some new features to the grammars.
The rules are interpreted in a more declarative way, which makes
cautious context and ordering irrelevant.
One rule corresponds to many logical formulas,
where each condition interpreted as a target---this makes the number of the rules
potentially smaller. 
Ordering can be preserved or discarded;
in the latter case, we solve eventual rule conflicts by finding a
solution that discards the least number of rule applications.
We test our implementation by parsing texts in the order of
10,000s--100,000s words, using grammars with hundreds of rules.
\end{abstract}


\section{Introduction and previous research}

Constraint Grammar (CG) \cite{karlsson1995constraint} is a relatively
young formalism, born out of practical need for a robust and
language-independent method for part-of-speech tagging.
%It belongs to the reductionist family of parsing
%strategies, along with e.g. Finite-State Intersection Grammar (FSIG) \cite{koskenniemi90}.
In this work, we present CG %\footnote{Roughly compatible with CG-2}
as a Boolean satisfiability (SAT) problem, and describe an implementation
using a SAT solver. This is attractive from several reasons: formal logic is
well-studied, and serves as an abstract language to reason about the
properties of CG. Constraint rules encoded in logic capture richer
dependencies between the tags than standard CG.

Applying logic to reductionist grammars has been explored earlier by \cite{lager98,lager_nivre01}, but it was never adopted for use.
% ; logic programming was too slow to be used for tagging or parsing. 
Since those works, SAT solving techniques have improved significantly \cite{marques_silva2010}, and they are used in domains such as microprocessor design and computational 
biology---these problems easily match or exceed CG in complexity. 
Due to these advances, we were able to revisit the idea and develop it
further. 

Our work is primarily inspired by \cite{lager98}, which presents constraint
rules as a disjunctive logic program, and \cite{lager_nivre01}, which
reconstructs four different formalisms in first-order logic.
Other works combining logic to CG include
\cite{lindberg_eineborg98ilp} and \cite{asfrent14}, both using Inductive Logic Programming to learn CG rules from a tagged corpus.
%We explore different approaches to ordering. 
%In the case of unordered rules, it resembles Finite-State Intersection Grammar \cite{koskenniemi90}.
%See also \cite{lager01transformation} for discussion of ordering of the CG rules.


\section{CG as a SAT problem}
Let us demonstrate our approach with the following example in Spanish.

\begin{verbatim}
"<la>"
        "el" det def f sg
        "lo" prn p3 f sg
"<casa>"
        "casa" n f sg
        "casar" v pri p3 sg
        "casar" v imp p2 sg
\end{verbatim}

The ambiguous passage can be either a noun phrase, \emph{la}\texttt{<det>} \emph{casa}\texttt{<n>} 
`the house'  or a verb phrase \emph{la}\texttt{<prn>}  \emph{casa}\texttt{<v><pri><p3>} `(he/she) marries her'. 
We add the following rules:

\begin{itemize}
\item [] \texttt{REMOVE prn IF (1 n) ;} \\
             \texttt{REMOVE det IF (1 v) ;}
\end{itemize}

Standard CG will apply one  of the rules to the word \emph{la}; 
either the one that comes first, or by some other heuristic. 
The second rule will not fire, because it would remove the last
reading. 
If we use the cautious mode (\texttt{1C n} or \texttt{1C v}), which
 requires the word in the context to be fully disambiguated, 
neither of the rules will be applied.
In any case, all readings of \emph{casa} are left untouched by these rules.

The SAT solver performs a search, 
and starts building possible models that satisfy both constraints. 
In addition to the given constraints, we have default rules to emulate
the CG principles: an analysis is true if no rule affects it,
and at least one analysis for each word is true---the notion of
``last'' is not applicable.

With these constraints, we get two solutions. The interaction of the rules regarding \emph{la}  disambiguates \emph{casa} for free, and ordering of the rules doesn't matter. 

\begin{enumerate}
\item [\texttt{1)}]
\begin{verbatim}
"<la>"
        "el" det def f sg
"<casa>"
        "casa" n f sg
\end{verbatim}
\item [\texttt{2)}]
\begin{verbatim}
"<la>"
        "lo" prn p3 f sg
"<casa>"
        "casar" v pri p3 sg
        "casar" v imp p2 sg
\end{verbatim}
\end{enumerate} 

% Without more context or additional rules we cannot fully disambiguate the passage,
% but unlike with standard CG, we get only legal combinations in one solution.



\noindent The most important differences between the traditional and
the SAT-based approach are described in the following sections.

\subsection{Rules disambiguate more}
Considering our example phrase and rules, the standard CG implementation
can only remove readings from the target word (\texttt{prn} or
\texttt{det}). The SAT-based implementation interprets the rules as
``determiner and verb together are illegal'', and is free to take action that concerns also the word in the condition (\texttt{n} or \texttt{v}).

This behaviour is explained by simple properties of logical formulae.
When the rules are applied to the text, they are translated into
implications: \texttt{REMOVE prn IF (1 n)} becomes
 \emph{casa}\texttt{<n>} $\Rightarrow$ $\neg$\emph{la}\texttt{<prn>},
 which reads ``if the \texttt{n} reading for \emph{casa} is true, then
 discard the \texttt{prn} reading for \emph{la}''.
Any implication $a\,\Rightarrow\,b$ can be represented as a disjunction
$\neg a\,\vee\,b$; intuitively, either the antecedent is false
and the consequent can be anything, or the consequent is true and the
antecedent can be anything.
Due to this property, our rule translates into the disjunction 
$\neg$\emph{casa}\texttt{<n>} $\vee$ $\neg$\emph{la}\texttt{<prn>},
which is also equivalent to another implication, 
 \emph{la}\texttt{<prn>} $\Rightarrow$ $\neg$\emph{casa}\texttt{<n>}.
This means that the rules are logically flipped: \texttt{REMOVE prn IF
  (1 n)} translates into the same logical formula as  \texttt{REMOVE n
  IF (-1 prn)}. 
A rule with more conditions corresponds to many rules, each condition
taking its turn to be the target. % of removal or selection.

% \begin{itemize}
% \item [] \texttt{REMOVE n IF (-1 prn) ;} \\
%          \texttt{REMOVE v IF (-1 det) ;}
% \end{itemize}

% SAT-based approach gives identical results with both sets of rules,
% whereas the standard CG would remove one reading from \emph{casa} and leave \emph{la} ambiguous.
% Testing this property with more complex rules and larger rule sets remains to be done.

%Rules with more conditions translate into many rules; rules with negation become complements (\texttt{(*)-X} for \texttt{NOT X}). Rules which require the condition to be unambiguously tagged, don't have an equivalent flip in the standard CG.
% We did not expect much practical benefits, save for realising that some rules are bad by having to think further what it implies,
%Out of interest, we manually flipped a small grammar and tested it against the original.
% \todo{The results show  }
%\begin{itemize}
%\item []          \texttt{SL Inf IF (-2 V-MOD) (-1 "not");} \\
%$\rightarrow$\texttt{SL V-MOD   IF (1 "not") (2 INF);} \\
%$\rightarrow$\texttt{SL "not" IF (-1 V-MOD) (1 Inf);}
%\item []           \texttt{SL Foo IF (NOT 1 Bar)} \\
%$\rightarrow$\texttt{SL (*)-Foo if (-1 Bar)}
%\end{itemize}


\subsection{Cautious context is irrelevant}
% Rather than waiting for a word to get disambiguated, the SAT solver starts by 
% making assumptions (e.g. ``\emph{casa} is a noun'') and working under them,
% discarding the assumption if it doesn't lead to a model that satisfies
% all constraints.

Traditional CG relies on that applying the rule set iteratively:
some rules fire during the first iteration, either because their
conditions don't require cautious context, or because some words are
unambiguous to start with. This makes some more words unambiguous, and
new rules can fire during the second iteration.

In SAT-CG, the notion of cautious context is irrelevant. Instead of
removing readings immediately,  each rule generates a  number of
implications, and the SAT solver tries to find a model that will satisfy them. 


Let us continue with the earlier example. 
We can add a word to the input:
\begin{itemize}
\item [] \emph{la casa grande} `the big house'
\end{itemize}
and a rule that removes verb reading, if the word is followed by an adjective:
\begin{itemize}
\item [] \texttt{REMOVE v IF (1 adj) ;}
\end{itemize}

% The SAT solver has already the clauses produced by the previous rules.
% \emph{casa}\texttt{<n>} $\Rightarrow$ $\neg$\emph{la}\texttt{<prn>}
% and   \emph{casa}\texttt{<v>} $\Rightarrow$ $\neg$\emph{la}\texttt{<det>}
The new rule adds the implication
 \emph{grande}\texttt{<adj>} $\Rightarrow$
 $\neg$\emph{casa}\texttt{<v>}, which will
disambiguate  \emph{casa} to a noun\footnote{Assuming that
  \texttt{adj} is the only reading for \emph{grande}, it must be true,
  because of the restriction that at least one analysis for each word
  is true. Then the implication has a true antecedent (\emph{grande}\texttt{<adj>}), thus its
  consequent ($\neg$\emph{casa}\texttt{<v>}) will hold.}. 
As the status of \emph{casa} is resolved, the SAT solver can now
discard the model where \emph{casa} is a verb and \emph{la} is a
pronoun
%---all these decisions are connected---
and we get a unique solution with \texttt{det n adj}.
% Now \emph{casa}\texttt{<n>} is true, so \emph{la}\texttt{<prn>} must be false. 
%Because \emph{la}\texttt{<prn>} is false,  \emph{casa} cannot
% be a \texttt{v}, and we get a unique solution with \texttt{det n adj}.

Contrast this with the behaviour of the standard CG.
With the new rule, standard CG will also remove the verb reading from \emph{casa}, 
but it is in no way connected to the choice for \emph{la}. It all
depends of the order of the two rules; if the \texttt{det} reading of
\emph{la} is removed first, then we are stuck with that choice.
If we made the first rules cautious, that is, keeping the determiner
open until \emph{casa} is disambiguated, then we get the same
result as with the SAT solver.
Ideally, both ways of grammar writing should yield similar results;
traditional CG rules are more imperative, and SAT-CG
rules are more declarative.

% The SAT-based approach only removes readings after it has enough
% evidence to do that. From the grammar writer perspective, this removes
% a burden of having to decide whether the rule should be cautious or
% not---the SAT solver will only take action the surrounding context
% supports the decision.

% \todo{Unordered rules: also not applicable anymore to apply rules
% iteratively; there's no ``this rule doesn't fire now but will after
% applying X and Y'', it's all just implications ``this rule will fire
% if this is true'' and let the SAT solver find if those rules can apply
% peacefully to the same input.}


\subsection{Rules can be unordered}
\label{sec:unord}

As hinted by the previous property, SAT solver doesn't need a fixed
order of the rules.
Applying a rule to a sentence produces a number of clauses,
and those clauses are fed into the SAT solver.
However, in the unordered scheme, some information is lost: the
following rule sets would be treated identically, whereas in the
traditional CG, only the second would be considered as a bad order.

\begin{itemize}
\item [\texttt{1)}] \texttt{REMOVE v IF (-1 det) ;} \\
         \texttt{SELECT v ;}
\item [\texttt{2)}] \texttt{SELECT v ;} \\
         \texttt{REMOVE v IF (-1 det) ;} 
\end{itemize}

Without order, both of these rule sets will conflict, if applied to an
input that has sequence \texttt{det v}.
The SAT solver is given clauses that tell to select a verb and remove a
verb, and it cannot build a model that satisfies all of those clauses.
To solve this problem, we create a variable for every instance of rule application, and request a solution where maximally many of these variables are true.
If there is no conflict, then the maximal solution is one where all of
these variables are true; that is, all rules take action.


In case of a conflict, SAT solver makes it possible to discard only
minimal amount of rule applications. Continuing with the example,
it is not clear which instances would be discarded, but if the rules
were part of a larger rule set, and in the context the REMOVE rule was
the right one to choose, it is likely that the interaction between the desired
rules would make a large set of clauses that fit together, and the
SELECT rule would not fit in, hence it would be discarded. 

This corresponds loosely to the common design pattern in
CGs, where there is a number of rules with the same target, ordered
such that more secure rules come first,
with a catch-all rule with no condition as the last resort, to be
applied if none of the previous has fired.
The order-based heuristic in the traditional CG is replaced by a more
holistic behaviour: if the rules conflict, discard the one that seems
like an outlier.

%With the added interaction between rules, catch-all rules might even be less 
%necessary. However, this is just speculation, we have not tested this effect.


%We can apply this for the whole grammar, or for one section at a time.

%The design of unordered rules can lead to new ways of writing CGs,
%potentially with less mental effort to the writer, but also less transparent. 

%By testing against gold standard, we see that the
%unordered scheme not optimal for applying ready-made
%CGs, where the order is a crucial detail.

We can also emulate order with SAT-CG. To do that, we enter clauses
produced by each rule one by one, and assume the solver state reached
so far is correct. If a conflict is introduced by new clauses, discard
them and move on to the next rule.
By testing against gold standard, we see that this scheme works better
with ready-made CGs, which are written with ordering in mind.
It also runs slightly faster than the unordered version.
%the performance, because the maximisation problems are smaller. 
%We have also experimented with sections, and 
\\


%  that it is possible to write a small grammar, 
% which, when run with the unordered scheme, disambiguates more than the
% same grammar run with VISL CG-3. 
% However, when tested with grammars that are written for the original
% CG, SAT-CG loses with both strategies, but emulating order fares better.

% Finite-state implementations of CG \cite{koskenniemi92} also have logically unordered rules. 
% \todo{Inari: check if Tapanainen 1996 discuss ordering}



\noindent These three features influence the way that rules are written. 
We predict that less rules are needed; whether this holds in the order
of thousands of rules remains to be tested. On one hand, getting rid
of ordering and cautious context could ease the task of the grammar
writer, since it removes the burden of estimating the best sequence of
rules and whether to make the them cautious. On the other
hand, lack of order can make the rules less transparent, and might not scale up for larger grammars.


\section{Evaluation}
\label{sec:eval}

For evaluation, we measure the performance against the state of the
art CG parser VISL CG-3.
% both in terms of accuracy and execution time.
SAT-CG fares slightly worse for accuracy, and significantly worse for execution time.
The results are presented in more detail in the following sections.

%This suggests that our implementation should not compete with existing
%state-of-the-art, but rather it has value as a way of relating the CG
%formalism to wider context in the theory of computer science.
%In Section~\ref{sec:apps} we discuss more about possible applications.



\subsection{Performance against VISL CG-3}


We took a manually tagged
corpus\footnote{https://svn.code.sf.net/p/apertium/svn/branches/apertium-swpost/apertium-en-es/es-tagger-data/es.tagged}
containing approximately 22,000 words of Spanish news text, 
and a small constraint grammar\footnote{https://svn.code.sf.net/p/apertium/svn/languages/apertium-spa/apertium-spa.spa.rlx}, produced independently of the authors.
% We ignored substitute rules, but kept subreadings and unification, even though our implementation doesn't handle them.
We kept only select and remove rules, after which the grammar had 261 rules.
With this setup, we produced an ambiguous version of the tagged
corpus, and ran both SAT-CG and VISL CG-3 on it.
Treating the original corpus as the gold standard, the disambiguation
by  VISL CG-3 achieves F-score of 82.6 \%, ordered SAT-CG 81.5 \%  and
unordered SAT-CG 79.2 \%. 
We did not test with other languages or text genres due to the lack of
available gold standard.
%This result suggests that that when running grammars that are written
%with the traditional CG in mind, SAT-CG loses with both ordering
%strategies, but emulating order fares better.

We also wanted to test the hypothesis that SAT-CG needs different
kinds of rules to perform well. We took the base grammar and started
handcrafting rules; with our best performing and most concise
grammar\footnote{https://github.com/inariksit/cgsat/blob/master/data/spa\_smallset.rlx}
of just 19 rules, unordered SAT-CG achieves 85.3 \% and VISL CG-3 85.9
\%. This experiment is naturally very small and might be explained by
overfitting or mere chance, but it seems to indicate that rules that
work well with SAT-CG, are also good for traditional CG.
% It was possible to attain a rule set for which the unordered SAT-CG
% works better (\textless0.5 \%), but it required trying
% subsequences of the 19-rule set in a brute force manner---this hardly
% presents any real life use case.



% Similar patterns were observed with small (\textless{}20) rule sets
% written by the authors; depending on the subset, SAT-CG and VISL CG-3 had
% a difference of at most $\Mypm$ 1.5 \%. 
% Introducing rules one by one up to 19, the
% performance improved in a very similar rate, with less than 0.5 \%
% difference between the systems at each new rule.
% We did not evaluate on other languages or text genres, due to lack of suitable test data.

% Additional tests could include plugging SAT-CG into Apertium
% translation pipeline, and comparing the translation quality.

\subsection{Time}

The worst-case complexity of SAT is exponential, whereas the standard
implementations of CG are polynomial, but with advances in SAT solving
techniques, the performance in the average case in practice is much more feasible than in the previous works done in 90s--00s.
We used the open-source SAT solver MiniSat \cite{een04sat}.


We tested the performance by parsing Don Quijote (384,155 words) with
the same Spanish grammars as in the previous experiment. 
Table~\ref{table:time} shows execution times compared to VISL CG-3;
SAT-CG\textsubscript{u} is the unordered scheme and
SAT-CG\textsubscript{o} is the ordered.
% For both systems, the number of rules in the grammar affects the performance more than the word count.
From the SAT solving side, maximisation is the most costly operation. 
Emulating order is slightly faster, likely because the maximisation problems are smaller.
In any case, SAT does not seem to be the bottleneck: with 261 rules,
the maximisation function was called 147,253 times, and with 19 rules,
132,255 times, but 
%However, with both rule sets, half of the sentences in Don Quijote
%needed less than 6 calls of maximise, and 75 \% of the sentences
%needed less than 14.
the differences in the execution times are much larger, which suggests
that there are other reasons for the worse performance. 
This is to be expected, SAT-CG is currently just a naive
proof-of-concept implementation with no optimisations.

\begin{table}
  \centering
  \begin{tabular}{|c|c|c|c|}
     \hline
     \textbf{\# rules} &  \textbf{SAT-CG\textsubscript{u}} & \textbf{SAT-CG\textsubscript{o}} & \textbf{VISL CG-3} \\ \hline
      19   & 39.7s &  22.1s   & 4.2s\\ %\hline
      99   & 1m34.1s & 1m14.9s & 6.1s \\ %\hline
      261  & 2m54.1s & 2m31.6s & 10.7s \\ \hline
  \end{tabular}
  \caption{Execution times for 384,155 words.}
  \label{table:time}
\end{table}

\section{Applications}
\label{sec:apps}
As described in Section~\ref{sec:eval}, our implementation is not
competetive with the state of the art. It is more fruitful to focus on
things where the SAT-based representation can make an impact.
One such thing is grammar analysis\footnote{We thank Eckhard Bick for
  the suggestion.}.
There has been work on automatic tuning of hand-written CGs
\cite{bick2013tuning}, but to our knowledge, no tools which would
search for inconsistencies or unoptimal design in order to point it out to the grammar writer.

The sequential application of traditional CG rules is good for
performance and transparency. As soon as a rule takes action, the analyses
are removed from the input, and next rules get the modified sentence
as their input. 
% At the execution of rule, there is no way to go back to earlier rules and undo them. 
Thus there is no way to know which part comes directly from the
raw input and which part from applying previous rules.

A conflict in an ordered scheme can be defined as 
a set of two or more rules, such that applying the first makes the
next rules impossible to apply, regardless of input.
We can reuse the example from Section~\ref{sec:unord}:

\begin{itemize}
\item [] \texttt{SELECT v ;} \\
         \texttt{REMOVE v IF (-1 det) ;}
\end{itemize}

The first rule selects the verb always, removing all other readings,
and the second rule removes verb reading, given certain condition.
If the rules are introduced in a different order, there is no
conflict: the REMOVE rule would not remove verb readings from all
possible verb analyses, so there is a possibility for the SELECT rule
to fire, as long as the input has verbs

Ordered SAT-CG can be used to detect conflicts without any
modifications, as a side effect of its design. 
After applying each rule, it stores the clauses
produced by it and commits to them---even if the new rules cannot
change the earlier decisions, the SAT solver still retains the
dependencies.
Given that each application of a rule gets a variable,
in case of a conflict, the program detects the particular
application that violates the previous clauses, with the sentence
where it is applied. Thus we get feedback which rule fails, and on which
particular word(s).

This conflict solving can be done per section, or for the whole grammar. 
In case of section-based application, we run each section on the
input, and give the output as a fresh input to the new section, discarding
all clauses. Alternatively, we can let the rules interact with each
other regardless of the section boundaries.

The unordered scheme with maximisation-based conflict solving (see Section~\ref{sec:unord}) is not feasible for this task. 
The whole definition of conflicts depends on ordering, and it would
not differentiate between the case where \texttt{SELECT v} comes
before \texttt{REMOVE v IF (-1 det)} or after.
On the other hand, an unordered formalism such as Finite-State
Intersection Grammar \cite{koskenniemi90} would benefit from the
maximisation-based technique in conflict handling.

For future work, we intend to apply the SAT solver for corpus-free
conflict testing. Let us illustrate the idea with the same two rules,
\texttt{REMOVE v IF (-1 det)} and \texttt{SELECT v}
in both orders.
Assume we have tag set \texttt{\{det, n, v, sg, pl\}}. Then we
can ask the SAT solver a question if there exists an input which
satisfies our constraints: both rules, applied in the order, remove
something from the input.
SAT solver tells us that with sentence length 2 and maximum 4 readings
for the whole sentence, there are several inputs that
satisfy the constraints for the first rule set, but none that
satisfies the second rule set: for instance


\begin{itemize}
\item []
\begin{verbatim}
"<w1>"
        det
        v
"<w2>"
        n
        v
\end{verbatim}
\end{itemize}
Thus we can say that the first rule set is sane, but the second rule
set is conflicting. 
Implementing and testing this on a larger scale is left for future work.


% SELECT (a) IF (0 PALJON + Nom + Sg) (1 N + Nom + Sg) ; # PALJO VALITTAMINEN
% SELECT (a) IF (0 PALJON + Par) (1 N + Par + Sg) ;
% SELECT (a) IF (0 PALJON + LOC-CASE) (1 N + 1 LOC-CASE + Sg) ;
% REMOVE (a) IF (0 PALJON) ; # "on asetettu paljon haltijaksi"

\section{Conclusions}

SAT-solvers are nowadays powerful enough to be used for dealing with
Constraint Grammar. A logic-based approach to CG has possible
advantages over more traditional approaches; a SAT-solver may
disambiguate more words, and may do so more precisely. Also, the
SAT-solver requires less rules, and these rules are simpler. 
\todo{proper conclusions for the new stuff}
% The ordering of rules is something we found was incompatible with a logic-based approach. We compensate this by maximising rule applications. Whether this is an advantage or disadvantage remains to be seen. Our initial experimental results are promising.


\section*{Acknowledgments}

We thank Eckhard Bick, Tino Didriksen, Francis Tyers and Anssi
Yli-Jyr{\"a} for comments and suggestions, as well as the anonymous
reviewers and everyone who participated in the discussion at the CG workshop.

% Do not number the acknowledgment section. Do not include this section
% when submitting your paper for review.

\bibliographystyle{acl}
\bibliography{cg}


\end{document}
