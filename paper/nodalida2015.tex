%
% File nodalida2015.tex
%
% Contact beata.megyesi@lingfil.uu.se
%
% Based on the instruction file for EACL 2014
% which in turn was based on the instruction files for previous 
% ACL and EACL conferences.

\documentclass[11pt]{article}
\usepackage{nodalida2015}
\usepackage{times}
\usepackage{mathptmx}
\usepackage{fixltx2e}
%\usepackage{txfonts}
\usepackage{url}
\usepackage{latexsym}
\usepackage{cite}
\usepackage{authordate1-4}
\usepackage{multirow}
\special{papersize=210mm,297mm} % to avoid having to use "-t a4" with dvips 
%\setlength\titlebox{6.5cm}  % You can expand the title box if you really have to

\usepackage{color}
\newcommand{\todo}[1]{{\color{cyan}\textbf{[TODO: }#1\textbf{]}}}
\usepackage{tikz}
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) --
  (.25,.15) -- cycle;}
\newcommand{\Mypm}{\mathbin{\tikz [x=1.4ex,y=1.4ex,line width=.1ex] \draw (0.0,0) -- (1.0,0) (0.5,0.08) -- (0.5,0.92) (0.0,0.5) -- (1.0,0.5);}}%

\title{Constraint Grammar as a SAT problem}

\author{Inari Listenmaa \and Koen Claessen \\
 Chalmers University of Technology, Gothenburg, Sweden \\
 {\tt \{inari,koen\}@chalmers.se} }

\date{\today}

\begin{document}
\maketitle

%\begin{abstract} \end{abstract}


\section{Introduction}

We represent Constraint Grammar (CG) \cite{karlsson1995constraint} 
as a Boolean satisfiability (SAT) problem.
This is attractive from several reasons: formal logic is
well-studied, and serves as an abstract language to reason about the
properties of CG. Constraint rules encoded in logic capture richer
dependencies between the tags than standard CG.

Applying logic to reductionist grammars has been explored earlier by \cite{lager98,lager_nivre01}, but it was never adopted for use.
% ; logic programming was too slow to be used for tagging or parsing. 
Since those works, SAT solving techniques have improved significantly \cite{marques_silva2010}, and they are used in domains such as microprocessor design and computational 
biology---these problems easily match or exceed CG in complexity. 
Due to these advances, we were able to revisit the idea and develop it
further. 

Encoding CG in logic increases computational complexity, 
but as a tradeoff, it could simplify the grammar writing.
Due to representing the rules as implications, cautious context
condition becomes irrelevant.
One rule corresponds to many logical formulas (each condition being
the target), which makes the number of the rules potentially smaller.
Ordering can be preserved or discarded; in the latter case, we solve
eventual rule conflicts by finding a solution that discards the least
number of rule applications.
% our experiments show that it is possible to write a small grammar, 
% which, when run with SAT-CG, disambiguates more than the same
%grammar run with VISL CG-3.

We test our implementation by parsing texts in the order of
10,000s--100,000s words, using grammars with hundreds of rules.



%SAT solving is based on a technique called unit propagation:
%a set of complex Boolean clauses is simplified, starting from unit
%clauses, which consist of just a single variable, and working up to a
%solution, where all variables in the set have a True or False value.


\section{Related work}
\label{sect:related}

Our work is inspired by \cite{lager98}, which presents constraint rules as a disjunctive logic program,
and \cite{lager_nivre01}, which reconstructs 4 different formalisms from a logical point of view.
\cite{lindberg_eineborg98ilp,asfrent14} use Inductive Logic Programming to learn CG rules from a tagged corpus.
We explore different approaches to ordering. In the case of unordered
rules, it resembles Finite-State Intersection Grammar \cite{koskenniemi90}.
See also \cite{lager01transformation} for discussion of ordering of the CG rules.
\section{CG as a SAT problem}
Let us demonstrate our approach with the following example in Spanish.

\begin{verbatim}
"<la>"
        "el" det def f sg
        "lo" prn p3 f sg
"<casa>"
        "casa" n f sg
        "casar" v pri p3 sg
        "casar" v imp p2 sg
\end{verbatim}

The ambiguous passage can be either a noun phrase, \emph{la}\texttt{<det>} \emph{casa}\texttt{<n>} 
`the house'  or a verb phrase \emph{la}\texttt{<prn>}  \emph{casa}\texttt{<v><pri><p3>} `(he/she) marries her'. 
We add the following rules:

\begin{itemize}
\item [] \texttt{REMOVE prn IF (1 n) ;} \\
             \texttt{REMOVE det IF (1 v) ;}
\end{itemize}

Standard CG will apply one\footnote{To be more cautious, we could require the word at position +1 be disambiguated fully (\texttt{1C} instead of \texttt{1}), but in that case, 
neither of the rules would be applied.} of the rules to the word \emph{la}; 
either the one that comes first, or by some other heuristic. 
The second rule will not fire, because it would remove the last reading. 
All readings of \emph{casa} are left untouched by these rules.

The SAT solver performs a search, 
and starts building possible models that satisfy both constraints. 
In addition to the given constraints, we have default rules to emulate
the CG principles: an analysis is true if no rule affects it,
and at least one analysis for each word is true---the notion of
``last'' is not applicable.

With these constraints, we get two solutions. The interaction of the rules regarding \emph{la}  disambiguates the POS of \emph{casa} for free, and ordering of the rules doesn't matter. 

\begin{enumerate}
\item [\texttt{1)}]
\begin{verbatim}
"<la>"
        "el" det def f sg
"<casa>"
        "casa" n f sg
\end{verbatim}
\item [\texttt{2)}]
\begin{verbatim}
"<la>"
        "lo" prn p3 f sg
"<casa>"
        "casar" v pri p3 sg
        "casar" v imp p2 sg
\end{verbatim}
\end{enumerate} 

% Without more context or additional rules we cannot fully disambiguate the passage,
% but unlike with standard CG, we get only legal combinations in one solution.



\noindent The most important differences between the traditional and the SAT-based approach are summarised below:

\paragraph{Condition of being unambiguously tagged is irrelevant.}
Rather than waiting for a word to get disambiguated, the SAT solver starts by 
making assumptions (e.g. ``\emph{casa} is a noun'') and working under them,
discarding the assumption if it doesn't lead to a model that satisfies
all constraints.

The traditional CG relies on that applying the rule set iteratively,
some rules fire the first time and make way for new rules to fire for
the second time.
For SAT-based CG, we present the rules as implications:
``if the \texttt{n} reading for \emph{casa} is true, then discard the
\texttt{prn} reading''. Each rule generates a list these implications,
and the SAT solver is left with the task of finding a model that will
satisfy them. 

Let us continue with the earlier example. 
We can add a word to the sentence, \emph{la casa grande} `the big house',
and a rule that removes verb if followed by an adjective.
\begin{itemize}
\item [] \texttt{REMOVE v IF (1 adj) ;}
\end{itemize}
Then the additional clauses will make it impossible for \emph{casa} to
be a verb\footnote{If \texttt{adj} is the only reading for
\emph{grande}, it must be true, because of the restriction that at
least one analysis for each word is true. Then the implication
\texttt{grande<adj> => $\neg$casa<v>} has a true antecedent, thus
its consequent will hold.}, so we will get a unique solution with \texttt{det n adj}.
Standard CG will also remove the verb reading, 
but remember the beginning: if the \texttt{det} reading of \emph{la}
was removed first, then we are stuck with that choice.

% \todo{Unordered rules: also not applicable anymore to apply rules
% iteratively; there's no ``this rule doesn't fire now but will after
% applying X and Y'', it's all just implications ``this rule will fire
% if this is true'' and let the SAT solver find if those rules can apply
% peacefully to the same input.}


\paragraph{Rules can be unordered.}

As hinted by the previous property, SAT solver doesn't need a fixed
order of the rules.
Applying a rule to a sentence produces a number of clauses,
and those clauses are fed into the SAT solver.
However, in the unordered scheme, some information is lost: the
following rule sets would be treated identically, whereas in the
traditional CG, only the first would be considered as a bad order.

\begin{itemize}
\item [\texttt{1)}] \texttt{SELECT verb ;} \\
         \texttt{REMOVE verb IF (-1 det) ;} \\
         \texttt{REMOVE verb IF (-1 adj) ;} \\

\end{itemize}


\begin{itemize}
\item [\texttt{2)}] \texttt{REMOVE verb IF (-1 det) ;} \\
         \texttt{REMOVE verb IF (-1 adj) ;} \\
         \texttt{SELECT verb ;}
\end{itemize}

Without order, both of these rule sets will conflict, if applied to an
input that has sequence \texttt{det verb} or \texttt{adj verb}.
The SAT solver is fed clauses that tell to select a verb and remove a
verb, and it cannot build a model that satisfies all of those clauses.
To solve this problem, we create a variable for every clause
(\emph{instance of rule application}), and request a solution where maximally many of these variables are true.
If there is no conflict, then the maximal solution is one where all of
these variables are true; that is, all instances of rule application are kept.
In case of a conflict, SAT solver makes it possible to discard only
minimal amount of rule applications. For the example, assuming that
there are instances for both contexts for the REMOVE rules, then just
ignoring the SELECT rule will lead to maximal solution. 
This corresponds loosely to the common design pattern in
CGs, where there is a number of rules with the same target, ordered
such that more secure rules come first,
with a catch-all rule with no condition as the last resort, to be
applied if none of the previous has fired.

We can apply this for the whole grammar, or for one section at a time.



The design of unordered rules can lead to new ways of writing CGs,
potentially with less mental effort to the writer, but also less
transparent. By testing against gold standard, we see that the
unordered scheme not optimal for applying ready-made
CGs, where the order is a crucial detail.
We can also emulate order: enter clauses produced by each rule one by
one, and assume the solver state reached so far is correct; if a
conflict is introduced by new clauses, discard them and move on to
next.
This is also better for the performance, because the maximisation
problems are smaller.


%  that it is possible to write a small grammar, 
% which, when run with the unordered scheme, disambiguates more than the
% same grammar run with VISL CG-3. 
% However, when tested with grammars that are written for the original
% CG, SAT-CG loses with both strategies, but emulating order fares better.





The chosen heuristic produced the best results with examples in the order of tens or hundreds of rules.
Larger rule sets are yet to be tested.

% Finite-state implementations of CG \cite{koskenniemi92} also have logically unordered rules. 
% \todo{Inari: check if Tapanainen 1996 discuss ordering}

\paragraph{Rules disambiguate more.}
Considering our example phrase and rules, standard CG implementation
can only remove readings for the target word (\texttt{prn} or
\texttt{det}). The SAT-based implementation interprets the rules as
``determiner and verb together are illegal'', and is free to take action that concerns also the word in the condition (\texttt{1 n} or \texttt{1 v}).
This means that the rules are logically flipped: \texttt{REMOVE prn IF
  (1 n)} translates into the same logical formula as  \texttt{REMOVE n
  IF (-1 prn)}. A rule with more conditions corresponds to many
rules, each condition taking its turn to be the target of removal or selection. \\

% \begin{itemize}
% \item [] \texttt{REMOVE n IF (-1 prn) ;} \\
%          \texttt{REMOVE v IF (-1 det) ;}
% \end{itemize}

% SAT-based approach gives identical results with both sets of rules,
% whereas the standard CG would remove one reading from \emph{casa} and leave \emph{la} ambiguous.
% Testing this property with more complex rules and larger rule sets remains to be done.

%Rules with more conditions translate into many rules; rules with negation become complements (\texttt{(*)-X} for \texttt{NOT X}). Rules which require the condition to be unambiguously tagged, don't have an equivalent flip in the standard CG.
% We did not expect much practical benefits, save for realising that some rules are bad by having to think further what it implies,
%Out of interest, we manually flipped a small grammar and tested it against the original.
% \todo{The results show  }
%\begin{itemize}
%\item []          \texttt{SL Inf IF (-2 V-MOD) (-1 "not");} \\
%$\rightarrow$\texttt{SL V-MOD   IF (1 "not") (2 INF);} \\
%$\rightarrow$\texttt{SL "not" IF (-1 V-MOD) (1 Inf);}
%\item []           \texttt{SL Foo IF (NOT 1 Bar)} \\
%$\rightarrow$\texttt{SL (*)-Foo if (-1 Bar)}
%\end{itemize}


\noindent These three features influence the way that rules are written. 
We predict that less rules are needed; whether this holds in
the order of thousands of rules remains to be tested.
Getting rid of ordering could ease the task of the grammar writer,
since it removes the need to estimate the best sequence of rule
applications.

When conducting our tests, we have been able to construct a small grammar 
which, when run with the unordered scheme, disambiguates more than the
same grammar run with VISL CG-3. However, when tested with grammars
that are written for the original CG, SAT-CG loses with both ordering
strategies, but emulating order fares better. 
This suggests that our implementation should not compete with existing
state-of-the-art, but rather it has value as a way of relating the CG
formalism to wider context in the theory of computer science.
In Section~\ref{sec:apps} we discuss more about possible applications.


\section{Results and evaluation}
\label{sec:eval}
\paragraph{Time}

The worst-case complexity of SAT is exponential, whereas the standard
implementations of CG are polynomial, but with advances in SAT solving
techniques, the performance in the average case in practice is much more feasible than in the previous works done in 90s--00s.
We used the open-source SAT solver MiniSat \cite{een04sat}.

Table~\ref{table:time} shows the execution time compared to VISL CG-3. 
The number of rules in the grammar is more significant than the word
count; this holds also for the performance of VISL CG-3.
From the SAT solving side, maximisation is the most costly operation;
hence emulating ordering is faster, because maximisation problems are smaller.
Parsing Don Quijote (384,155 words) with the rule set of 261 rules,
the function was called 147,253 times, and with 19 rules, 132,255 times.
%However, with both rule sets, half of the sentences in Don Quijote
%needed less than 6 calls of maximise, and 75 \% of the sentences
%needed less than 14.
The difference in the execution times suggests that there are other
reasons for the worse performance---this is to be expected,
SATCG is currently just a naive proof-of-concept implementation with no optimisations.

\begin{table}
  \centering
  \begin{tabular}{|l|c|c|c|c|}
     \hline
   \textbf{\# words} & \textbf{\# rules} &  \textbf{SATCG\textsubscript{u}} & \textbf{SATCG\textsubscript{o}} & \textbf{VISL CG-3} \\ \hline
                384,155  & 19   & TODO &  23.1s   & 4.2s\\ %\hline
	        384,155  & 99   & TODO & 1m40.6s & 6.1s \\ %\hline
                384,155  & 261  & TODO & 2m36.7s & 10.7s \\ \hline
  \end{tabular}
  \caption{Execution times.}
  \label{table:time}
\end{table}

\paragraph{Performance against VISL CG-3}


We took a tagged corpus\footnote{https://svn.code.sf.net/p/apertium/svn/branches/apertium-swpost/apertium-en-es/es-tagger-data/es.tagged} of 21865 words for Spanish, 
and a small constraint grammar\footnote{https://svn.code.sf.net/p/apertium/svn/languages/apertium-spa/apertium-spa.spa.rlx}, produced independently of the authors.
% We ignored substitute rules, but kept subreadings and unification, even though our implementation doesn't handle them.
We only took select and remove rules (no substitute/iff), after which the constraint grammar had 261 rules.
With this setup, we took the text of the tagged corpus with all
ambiguities, and ran both SATCG and VISL CG-3 with the same grammar. 
Treating the corpus as the gold standard, the disambiguation by
SATCG achieves 75.09 \% correct result and VISL CG-3 75.80 \%.
Similar patterns were observed with small (\textless{}20) rule sets
written by the authors; depending on the subset, SATCG and VISL CG-3 had
a difference of at most $\Mypm$ 1.5 \%. 
Introducing rules one by one up to 19, the
performance improved in a very similar rate, with less than 0.5 \%
difference between the systems at each new rule.

% Additional tests could include plugging SATCG into Apertium
% translation pipeline, and comparing the translation quality.



\section{Applications and Future Work}
\label{sec:apps}
As described in Section~\ref{sec:eval}, our implementation is not
competetive with the state of the art. It is more fruitful to focus on
things where the SAT-based representation can make an impact.
One such thing is grammar analysis.

Traditionally, CG rules are applied deterministically and
sequentially; at the execution of rule, there is no way to
go back to earlier rules and undo them. Thus there is no way to know
what part of the input comes from the morphological analyser and what
part from applying previous rules.

A conflict can be defined as 
a set of two or more rules, such that applying the first makes the
next rules impossible to apply, regardless of input.
As a simple example, these rules could be

\begin{itemize}
\item [] \texttt{SELECT verb ;} \\
         \texttt{REMOVE verb IF (-1 det) ;}
\end{itemize}

The first rule selects the verb always, removing all other readings,
and the second rule removes verb reading, given certain condition.
If the rules are introduced in a different order, there is no
conflict: the REMOVE rule would not remove verb readings from all
possible verb analyses, so there is a possibility for the SELECT rule
to fire.

The way we implement SAT-CG is ideal for this kind of grammar
analysis. After applying each rule, it stores the clauses produced by
it and commits to them -- this makes the execution slow, but it
retains the dependencies.
Given the design that each rule application (instead of rule) gets a variable,
in case of a conflict, the program prints out the particular
application that violates the previous clauses, with the sentence
where it is applied. 
This conflict solving can be done per section, or for the whole grammar. 
In case of section-based, we run each section on the input, and give
the output as an input to the new section, discarding all clauses.

Maximisation-based conflict solving (conflicting rule set --> remove least
possible amount to get a non-conflicting rule set) is not feasible for this task. 
The whole definition of conflicts depends on ordering, and it would
not differentiate between the case where \texttt{SELECT verb} comes
before \texttt{REMOVE verb IF (-1 det)} or after.
On the other hand, a formalism such as FSIG would benefit from the
maximisation-based technique in conflict handling.




% SELECT (a) IF (0 PALJON + Nom + Sg) (1 N + Nom + Sg) ; # PALJO VALITTAMINEN
% SELECT (a) IF (0 PALJON + Par) (1 N + Par + Sg) ;
% SELECT (a) IF (0 PALJON + LOC-CASE) (1 N + 1 LOC-CASE + Sg) ;
% REMOVE (a) IF (0 PALJON) ; # "on asetettu paljon haltijaksi"

\section{Conclusions}

SAT-solvers are nowadays powerful enough to be used for dealing with Constraint Grammar. A logic-based approach to CG has possible advantages over more traditional approaches; a SAT-solver may disambiguate more words, and may do so more precisely. Also, the SAT-solver requires less rules, and these rules are simpler. The ordering of rules is something we found was incompatible with a logic-based approach. We compensate this by maximising rule applications. Whether this is an advantage or disadvantage remains to be seen. Our initial experimental results are promising.


% \section*{Acknowledgments}

% Do not number the acknowledgment section. Do not include this section
% when submitting your paper for review.

\bibliographystyle{acl}
\bibliography{cg}


\end{document}
