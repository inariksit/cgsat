\section{Introduction}
\label{sec:intro}

Constraint Grammar (CG, \cite{karlsson1995constraint})
% \citep[CG][]{karlsson1995constraint} 
is a method for disambiguating morphologically analysed text% and adding syntactic or dependency labels
. 
A grammar consists of rules that target specific analyses for selection or removal, based on contextual tests. For example, the following rule
\begin{itemize}
\item[] \texttt{REMOVE verb IF (-1C det) ;}
\end{itemize}
removes a verb reading from a word which is preceded by an unambiguously (C) tagged determiner.
Given a text, such as

\begin{verbatim}
"<the>"
        "the" det def
"<bear>"
        "bear" noun sg
        "bear" verb pl
\end{verbatim}

the rule will apply to the word \emph{bear}, and remove the analysis \texttt{verb pl}.
Rules are not allowed to remove the last remaining analysis: if  \texttt{verb pl} were the only analysis for \emph{bear}, then the rule would not apply, even if the condition is met.

CGs are valuable resources for rule-based NLP, especially for lesser resourced languages. They are robust and can be written without large corpora--only morphological analysis is needed. The formalism is lightweight and language-independent, and resources can be shared between related languages \cite{bick2006spanish}, \cite{lene_trond_linda2010}.
Mature CGs contain some thousands of rules, but even small CGs are shown to be effective \cite{lene_trond2011}.

As CGs grow larger, .

\cite{bick2013tuning} presents efforts to optimise hand-written CGs using machine learning techniques.
While Bick's experiments show improvements in results, the grammar writer is none the wiser why is the grammar better.
Our toolset is designed to complement the existing efforts.
The ideal use case would be a grammar writer, who wants to know e.g.

\begin{itemize}
\item Is there a sentence that triggers rule(s) X but not rule(s) Y?
\item Give a sentence that is ambiguous but doesn't trigger any rules
\item Does my grammar contain rules that contradict each other?
\item Does my grammar contain rules that will never fire?
\end{itemize}

The technique requires an existing morphological lexicon, but no corpus.
This makes it suitable also for languages without large corpora.
Authors writing grammars for well-resourced languages can also benefit from the technique, as an additional tool along with a gold standard corpus. 
Hand-annotated corpora are commonly used in the development of CGs, because they give immediate feedback whether a new rule increases or decreases accuracy, and by how large margin (\cite{voutilainen2004}). For a language with no free hand-tagged corpus available, \cite{tyers_reynolds2015} describe a method where they apply their rules to Wikipedia texts and pick 100 examples at random for manual check.

\section{Previous work}

This work draws inspiration from various sources.

\begin{itemize}
\item Methods for grammar writing \cite{voutilainen2004},  \cite{tyers_reynolds2015}
\item Optimising a hand-written CG \cite{bick2013tuning}
\item Encoding CG as a logic program \cite{lager98}, \cite{lindberg_eineborg98ilp},  \cite{lager01transformation}, \cite{asfrent14}, \cite{listenmaa_claessen2015}
\end{itemize}

Things you can get from corpus:

\begin{itemize}
\item \# times the rule was applied
\item \% times it was correct
\end{itemize}
Strengths: gives concrete feedback about the effect of rules. 
Good especially at the beginning stages of grammar writing. 
Sometimes you just want to know that a rule fired 500 times and was correct 490 times, rather than ``it is possible to construct a word sequence that will trigger this rule''.
The connection to the reality has also weak sides. This method will not notice a missed opportunity. What if instead of firing 500 times, it could have fired 1000 times if it had been placed earlier in the rule sequence.
Or the rule that was wrong in 60 \% of the time,

% \cite{voutilainen2004} state that the first 200 rules are probably enough to resolve 50--75 \% of ambiguities in the corpus used in the development. 

Things you can get from ML tuning:
\begin{itemize}
\item Variations in the place of the rule
\item Variations in the conditions (careful, ...) of the rule
\end{itemize}
Good side: try all combinations to find the best result. 
At a certain point, the grammar gets so big that it is hard to keep track of all the rules and their interactions. \cite{bick2013tuning} tries out combinations of moving rules in different sections or removing them in total, and in parallel, making their contexts stricter or less strict. 
This is a valuable tool, especially for grammars that are so big that it's hard to keep track of. Program can try all combinations whereas trying to make sense out of a huge set of rules would be hard for humans.
As a downside, the grammar writer will likely not know why exactly is the tuned grammar performing better.


Things you can get from SAT solver:
\begin{itemize}
\item Interaction of rules
\item Create word sequences to test what is possible and what can never happen
\end{itemize}




\todo{Relate to conf themes: "Methodologies and tools for LRs construction and annotation" and
"Validation and quality assurance of LRs"}

% * Describe problem: CGs are huge & prone to mistakes,
%  * we are looking at conflicts such as ...
%  * if you forgot a case
%  * some evidence that big CGs have conflicts and this is a real problem
%  * Eckhard's paper to explain why conflicting rules are a problem
%  * Goal: help grammar writer while they are writing the grammar, to avoid these kinds of problems
%  * Examples

% * Describe the technique

% * Preliminary results
%  - dutch & spanish
%  - mention scalability
%  - talk about size of SAT problem -- give number of SAT clauses for the last rule in the biggest grammar I have

% * Future work
%  - analysing different grammar formalisms
%  - asking different questions
%  - restrict yourself to readings that are actually words



