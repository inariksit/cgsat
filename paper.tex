\documentclass[a4paper, 11pt]{article}
\topmargin-2.0cm

\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{extramarks}
\usepackage{pagecounting}
\usepackage{color}
\usepackage[round]{natbib}
\usepackage{lipsum}
\usepackage{enumerate}
%\usepackage{tipa}
%\usepackage{gb4e}
\usepackage{graphicx}
\usepackage{amsmath, amsthm}
%\usepackage{colortbl}
\usepackage{caption}
\usepackage[T1]{fontenc}
\usepackage[a4paper]{geometry}
\usepackage{courier}
\usepackage{listings}
\lstset{
         basicstyle=\footnotesize\ttfamily, 
         numberstyle=\tiny,          
         numbersep=5pt,             
         tabsize=2,                
         extendedchars=true,      
         breaklines=true,        
         showspaces=false,      
         showtabs=false,       
         xleftmargin=17pt,
         framexleftmargin=17pt,
         framexrightmargin=5pt,
         framexbottommargin=4pt,
         showstringspaces=false 
 }
 \lstloadlanguages{
         Haskell
 }

\usepackage{url}

\advance\oddsidemargin-0.35in
\advance\evensidemargin-0.65in
\textheight9.5in
\textwidth6.5in

\newcommand{\hsp}{\hspace*{\parindent}}
\definecolor{gray}{rgb}{0.4,0.4,0.4}

\newcommand\blfootnote[1]{
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}
  \addtocounter{footnote}{-1}
  \endgroup
}

%\sectionfont{\large}

\begin{document}
\lstset{language=Haskell}
\pagestyle{fancy}
\lhead{\textcolor{gray}{Inari Listenmaa}}
\chead{\textcolor{gray}{\bf Grammar Formalisms}}
\rhead{\textcolor{gray}{LP2 2014}}
\lfoot{\textcolor{gray}{}}
\rfoot{\thepage}
\renewcommand{\headrulewidth}{0.5pt} 
\renewcommand{\footrulewidth}{0.5pt} 
\fancyfoot[C]{\footnotesize \textcolor{gray}{}} 

\centerline{ {\Large \bf Constraint Grammar} }
\vspace*{0.2cm}

\section{Introduction}

In this course paper, I describe the implementation of Constraint Grammar in Haskell, using a SAT solver to find a solution that fits all the constraints.

First I describe the existing implementations, followed by my own SAT-based solution.

\section{Constraint Grammar}

Constraint Grammar (CG) was first introduced by \cite{KarlssonTODO}. 
It a tool for disambiguating output by morphological analyser.
CG can run on unrestricted text, given that the morphological analyser
has large vocabulary.

Parsing is an action where an unstructured input is transformed into a
structured output. In a sense, applying CG rules on a text shouldn't
be considered as parsing: it doesn't really build a new structure,
such as phrase structure tree or dependency tree.
The grammatical information is already in the input, and applying the
rules leaves (ideally) only the correct options. 
It doesn't require that the text should be parsed as full units; it is
neither top-down or bottom up. Rules can have a context of specified
amount of words (e.g. 1 to the left; 2 to the right), unlimited amount
of words (e.g. anywhere to the left; 2 to the right and further from
that) or they can be limited by a barrier (e.g. anywhere to the right
until we see an adverb).

In the example below, we show possible tags for the sentence ``the bear sleeps''.

\begin{lstlisting}
the     <Det>
bear    <Noun, Sg>
        <Verb, Pl, Pres>
        <Verb, Inf>
sleep   <Noun, Pl>
        <Verb, Sg3, Pres>
\end{lstlisting}

We could disambiguate this sentence with two rules: 
\begin{enumerate}
\item Select noun (or remove verb) after determiner;
\item Select verb, if is preceded by noun and followed by a sentence boundary.
\end{enumerate}

We would go through the input twice. The first rule would fire at the
first pass: we find a case where there is something tagged as
\texttt{Det} followed by something with \texttt{Noun} among the
analyses. We will apply the rule where we select the noun reading, and
discard the two other options (present tense verb or nonfinite verb).

Then, at the next pass, we have two unambiguous tokens,
and we go through the input again, to see
if the first pass has created chances for new rules to
activate. Now we find a context, where there is an ambiguous word
preceded by a noun (\emph{bear}) and followed by a sentence boundary,
so we can apply rule 2. The finished analysis is as follows:

\begin{lstlisting}
the     <Det>
bear    <Noun, Sg>
sleep   <Verb, Sg3, Pres>
\end{lstlisting}

\subsubsection{Syntax}

``Because syntax, just as morphological disambiguation, relies on
elimination of alternatives, it is advantageous to introduce all
simple syntactic instantiations at once. Readings not having syntactic
labels after morphological analysis get them via morphosyntactic
mapping.''

e.g. it makes sense
7: [Lem "they",Pron,Subj,Nom,P3]
if we have a morph tag, like a pron, to label it already
since we know that they can only be SUBJ
and them can only be OBJ

CG can also be applied to shallow syntax. After having disambiguated
the text morphologically, we can apply possible syntactic labels. For
instance, a noun can have a syntactic role of subject, object or
predicative; and a verb in present tense 3rd person singular can be
only the main verb (possibly combined with a conjunction, e.g. ``the
bear eats and sleeps''). The next step is shown below; the analyses
chosen in the previous step are shown in the angle brackets, and potential
syntactic labels are fully capitalised and preceded by @. The sign >
in the tag \texttt{@DN>} expresses head/modifier relation determiner of the next head nominal to the right

\begin{lstlisting}
the     <Det>            @DN>    
bear    <N, Sg>          @SUBJ
                         @OBJ
                         @PREDC
sleep   <V, Sg3, Pres>   @MAINV
\end{lstlisting}

This set would be disambiguated by a syntactic constraint that would
select subject if followed by a finite verb form.

\cite{koskenniemi92} include also 4 types of clause boundaries (TODO read about
it), such as marking coordinated or subordinated clauses, or showing
beginning and end of an embedded clause.
%; so the parse would be complete if \emph{the} and \emph{bear} would belong to 

(c/p from koskenniemi paper)
``Rules in the CG formalism are typically dedicated
for one of the above tasks, and they are
executed as successive groups.
In finite-state syntax, rules are logically unordered.''




\section{Standard implementation(s)}

The first implementation, CG-1, was introduced in \cite{KarlssonTODO}. Karlsson describes the implementation as ``ad hoc`` and ``without any deeper technical contributions to parsing theory``, and adds that ideally, CG should be implemented with finite state methods.
CG-2, implemented by \cite{tapanainen1996}, used finite state technology. 
The latest version, CG-3, was implemented by \cite{TODO} without finite state technology. The implementation introduced new properties, such as ordering of the rules.

\begin{quote}
[--] the Lisp, C, and C++ implementations of the Constraint Grammar Parser are all fairly ad hoc rule interpreters without any deeper technical contributions to parsing theory. These implementations are not based on the use of well understood and theoretically sound parsing algorithms. Rather, they could be characterized as situation-action parsing programs. 
\end{quote}

\begin{quote}The whole finite-state grammar consists of a set of rules which
constrain the possible choices of word Interpretations, tags and
boundaries to only those which are considered grammatical. The entire grammar Is effectively equivalent to the (theoretical) intersection of all individual rule automata. However, such an intersection would be impractical to compute due to Its huge size.
The logical task for any finite-state parser in the current approach is
to compute the intersection of the unanalyzed sentence automaton and
each rule automaton. Actual parsing can be done in several alternative
ways which are guaranteed to yield the same result, but which vary in
terms of efficiency.
\end{quote}

\subsection{Workflow}

All implementations (TODO check) go through the input many times and apply all possible rules each time. 
After one pass, it may be possible to apply some rules that didn't fire the last time.


\subsection{Resolving conflicts}

For CG-1 and CG-2, ... sections? TODO

In CG-3, the rules are ordered. In case of a conflict, the rule that is described first is given priority.


\section{SAT based implementation}

SAT solving is based on a technique called unit propagation:
a set of complex Boolean clauses is simplified, starting from unit
clauses, which consist of just a single variable, and working up to a solution, where all variables in the set
have a True or False value.

Let us demonstrate this with a small example.
We have a set of variables describing properties of people: \texttt{is\_under\_18},
\texttt{has\_driving\_licence} and \texttt{is\_drunk}.

% For instance, the following constraints describe rules for driving a car.
% \begin{verbatim}
% can_drive
% has_driving_licence
% is_under_18
% is_drunk
% \end{verbatim}

% Next, we represent a possible situation in the world. In order to be allowed to drive, a person must have a driving licence and they must not be drunk. This is represented by the clause $can\_drive ∧\wedge has\_driving\_licence ∧\wedge \neg is\_drunk$. Furthermore, from the world knowledge, we know that in order to have a driving licence, one must be over 18. This is represented by the second clause.

Clause 1 describes a possible situation in a world: someone is behaving in away that makes you think of a hypothesis ``either they are underage or
drunk''. This is represented as \texttt{is\_under\_18} $\vee$
\texttt{is\_drunk}. Just by this clause we can't solve the reason for the
behaviour: it can be one of them or both.

Clause 2 comes from the world knowledge that in order to have a
driving licence, one must be over 18. The form of the clause is
obtained by applying negation distributively over the more intuitive
clause $\neg$ (\texttt{has\_driving\_licence} $\wedge$
\texttt{is\_under\_18}): it is not possible to both have driving
licence and be under 18.

\begin{enumerate}
\item \texttt{is\_under\_18} $\vee$ \texttt{is\_drunk}
\item ($\neg$ \texttt{has\_driving\_licence}) $\vee$ ($\neg$ \texttt{is\_under\_18})
\item \texttt{has\_driving\_licence}
\end{enumerate}

Clause 3 provides us some undeniable evidence that
the person has a driving licence. By this clause, 
we know that the variable \texttt{is\_under\_18} is not true.
Knowing that, we can eliminate \texttt{is\_under\_18} from the first
clause. 
The solution is below: the three variables must have these values in order to
satisfy the constraints.

\begin{itemize}
\item \texttt{is\_drunk} = True
\item \texttt{is\_under\_18} = False
\item \texttt{has\_driving\_licence} = True
\end{itemize}

SAT solving is used for many applications where constraints must be
satisfied, such as software and hardware verification.

\subsection{CG formulated in SAT}

We make each analysis a variable. For instance, the fifth line denotes
a hypothesis that the correct analysis of the 3rd item in the sentence
is \texttt{<V,Sg>}. We call this \texttt{Var 5}.

\begin{lstlisting}
((1,[Lem "the",Det]),Var 1)
((2,[Lem "bear",N,Sg]),Var 2)
((2,[Lem "bear",V,Pl]),Var 3)
((3,[Lem "sleep",N,Pl]),Var 4)
((3,[Lem "sleep",V,Sg]),Var 5)
((4,[Lem "in",Prep]),Var 6)
((4,[Lem "in",Adv]),Var 7)
((5,[Lem "the",Det]),Var 8)
((6,[Lem "house",V,Inf]),Var 9)
((6,[Lem "house",N,Sg]),Var 10)
\end{lstlisting}


We have defined our variables, but not yet any truth values. We can
start by doing two things:
\begin{enumerate}
\item Make unambiguous tokens true by default: e.g. \texttt{Var 1}
  shows that the reading \texttt{Det} for the first token must be true.
\item Make hypotheses of possible n-grams. In the example below, we
show bigrams: \texttt{(Var 1 $\wedge$ Var 2) $\vee$ (Var 1 $\wedge$ Var 3)}
means that the first two tokens have analyses \texttt{Det,N} or
\texttt{Det,V}.
\end{enumerate}

We could easily add a third rule: for ambiguous tokens, make sure that
only one reading can be true (or a less strict version, where all
readings can't be true). For instance, \texttt{Not (Var 2 $\wedge$ Var
  3)} would be the constraint that the second token can't be both
\texttt{N} and \texttt{V} at the same time. However,
\cite{KarlssonTODO} argues that CG cannot remove genuine ambiguities;
in a case where a sentence is genuinely ambiguous, all readings are
returned.



\begin{lstlisting}
Var 1
Var 8
(Var 1 :&&: Var 2) :||: (Var 1 :&&: Var 3)
(Var 2 :&&: Var 4) :||: ((Var 2 :&&: Var 5) :||: ((Var 3 :&&: Var 4) :||: (Var 3 :&&: Var 5)))
(Var 4 :&&: Var 6) :||: ((Var 4 :&&: Var 7) :||: ((Var 5 :&&: Var 6) :||: (Var 5 :&&: Var 7)))
(Var 6 :&&: Var 8) :||: (Var 7 :&&: Var 8)
(Var 8 :&&: Var 9) :||: ((Var 8 :&&: Var 10))
\end{lstlisting}
% Not (Var 2 :&&: Var 3)
% Not (Var 4 :&&: Var 5)
% Not (Var 6 :&&: Var 7)
% Not (Var 9 :&&: Var 10)

Another property of CG is that cannot remove all readings: if all
other analyses are eliminated, the remaining analysis must be
returned, even if it were to be eliminated at the next pass. 
However, this property isn't implemented in the SAT version.

\subsection{Workflow}

Assume we have a fragment ``both houses and cars''.
The word \emph{both} has analyses \texttt{CoordConj} and
\texttt{Pron}, and \emph{houses} is ambiguous between \texttt{N} and \texttt{V}.
We have in our rule set the following rules:

\begin{enumerate}
\item remove N after Pron
\item select N after *Conj
\item select CoordConj before another CoordConj
\end{enumerate}

In the previous implementations, neither of rules 1 and 2 would fire
before we have disambiguated \emph{both} with rule 3.
In this implementation, we are creating all clauses before giving
them to the SAT solver. We express these constraints as implications:
\begin{itemize}
\item \emph{both} is \texttt{Pron} $\Rightarrow$ remove \texttt{N} for \emph{houses}
\item \emph{both} is \texttt{CoordConj} $\Rightarrow$ select
  \texttt{N} for \emph{houses}
\end{itemize}

For lemmas with only one reading, this leads to redundant clauses,
such as \texttt{Not (Var 8) :||: Not (Var 8)}, but SAT solver will
take care of them.

\subsection{Data types}

\begin{lstlisting}
data Rule = Remove [Tag] Condition | Select [Tag] Condition

data Condition = C Position [Tag]
               | NOT Condition
               | AND Condition Condition
               | OR  Condition Condition 
\end{lstlisting}

The data type for Rule is either remove or select a list of tags, with condition(s).
For Condition, there are basic conditions (position and a list of context tags) and combined conditions, with constructors `NOT', `AND' and `OR'. For instance, the following rule is read as ``remove tag for any verb, if the lemma is \emph{bear} or there is a determiner or an article anywhere to the left''.

\begin{lstlisting}
verb = [V, V2, V3, VV, V2V, VS]
Remove verb (OR (C (Exactly 0)  [Lem "bear"])
                (C (AtLeast -1) [Det,Art])
            )
\end{lstlisting}

There is no special constructor for empty condition (ie. remove/select tag everywhere), but an empty tag list in a condition, i.e. \texttt{C \_ []} is assumed to mean that.

The data type for position can be exact n places or at least n places. The number 0 means the word itself, negative number means \emph{n} positions to the left and positive \emph{n} positions to the right.

\begin{lstlisting}
data Position = Exactly Integer | AtLeast Integer
 \end{lstlisting}

\subsection{Complex conditions}
Conditions constructed by OR are represented as a sequence, and AND as
parallel. In Haskell, I simply use nested lists: everything inside the
outer list is subject to OR, and within the lists AND. This is best
demonstrated by an example:

\begin{itemize}
\item \texttt{OR (OR C1 C2) C3} becomes \texttt{[[C1], [C2], [C3]]} 
\item \texttt{AND (AND C1 C2) C3} becomes \texttt{[[C1, C2, C3]]} 
\item \texttt{AND (OR C1 C2) C3} becomes \texttt{[[C1,C3], [C2,C3]]}
\end{itemize}

\subsection{Conflicts}
If you try to use conflicting rules, you get user error: mzero.

\subsection{Example run}

We show an example run for the sentence \emph{They are both happy and go to the house}. This is
taken from a real output of a morphological analyser, and was
initially ambiguous in the following ways:

\begin{itemize}
\item[] are
\begin{itemize}
\item[] \texttt{<''be'', V, Pres>}
\item[] \texttt{<''are'', N, Sg>}
\end{itemize}

\item[] both
\begin{itemize}
\item[] \texttt{<''both'', CoordConj>}
\item[] \texttt{<''both'',Det>}
\item[] \texttt{<''both'',Pron>}
\end{itemize}


\item[] go
\begin{itemize}
\item[] \texttt{<''go'', V, Inf>}
\item[] \texttt{<''go'', V, Pres>}
\item[] \texttt{<''go'', N, Sg>}
\end{itemize}

\item[] to
\begin{itemize}
\item[] \texttt{<''to'', Prep>}
\item[] \texttt{<''to'', Adv>}
\end{itemize}

\item[] house
\begin{itemize}
\item[] \texttt{<''house'', V, Inf>}
\item[] \texttt{<''house'', V, Pres>}
\item[] \texttt{<''house'', N, Sg>}
\end{itemize}
\end{itemize}

\begin{verbatim}
Tag sequence:
1: [Lem "they",Pron,Subj,Nom,P3]
2: [Lem "are",N,Sg]
3: [Lem "both",Pron]
4: [Lem "happy",Adj]
5: [Lem "and",CoordConj]
6: [Lem "go",V,Inf]
6: [Lem "go",V,Pres]
7: [Lem "to",Prep]
8: [Lem "the",Det]
9: [Lem "house",N,Sg]
\end{verbatim}

%If you want references on a separate page, uncomment the following command.
%\clearpage

%\begin{small}
%\bibliographystyle{plainnat}
%\bibliography{references}
%\end{small}

\end{document}

