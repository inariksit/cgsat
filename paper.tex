\documentclass[a4paper, 11pt]{article}
\topmargin-2.0cm

\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{extramarks}
\usepackage{pagecounting}
\usepackage{color}
\usepackage[round]{natbib}
\usepackage{lipsum}
\usepackage{enumerate}
%\usepackage{tipa}
%\usepackage{gb4e}
\usepackage{graphicx}
\usepackage{amsmath, amsthm}
%\usepackage{colortbl}
\usepackage{caption}
\usepackage[T1]{fontenc}
\usepackage[a4paper]{geometry}
\usepackage{courier}
\usepackage{listings}
\lstset{
         basicstyle=\footnotesize\ttfamily, 
         numberstyle=\tiny,          
         numbersep=5pt,             
         tabsize=2,                
         extendedchars=true,      
         breaklines=true,        
         showspaces=false,      
         showtabs=false,       
         xleftmargin=17pt,
         framexleftmargin=17pt,
         framexrightmargin=5pt,
         framexbottommargin=4pt,
         showstringspaces=false 
 }
 \lstloadlanguages{
         Haskell
 }

\usepackage{url}

\advance\oddsidemargin-0.35in
\advance\evensidemargin-0.65in
\textheight9.5in
\textwidth6.5in

\newcommand{\hsp}{\hspace*{\parindent}}
\definecolor{gray}{rgb}{0.4,0.4,0.4}

\newcommand\blfootnote[1]{
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}
  \addtocounter{footnote}{-1}
  \endgroup
}

%\sectionfont{\large}

\begin{document}
\lstset{language=Haskell}
\pagestyle{fancy}
\lhead{\textcolor{gray}{Inari Listenmaa}}
\chead{\textcolor{gray}{\bf Grammar Formalisms}}
\rhead{\textcolor{gray}{LP2 2014}}
\lfoot{\textcolor{gray}{}}
\rfoot{\thepage}
\renewcommand{\headrulewidth}{0.5pt} 
\renewcommand{\footrulewidth}{0.5pt} 
\fancyfoot[C]{\footnotesize \textcolor{gray}{}} 

\centerline{ {\Large \bf Constraint Grammar} }
\vspace*{0.2cm}

\section{Introduction}

In this course paper, I describe the implementation of Constraint Grammar in Haskell, using a SAT solver to find a solution that fits all the constraints.

First I describe the existing implementations, followed by my own SAT-based solution.

\section{Constraint Grammar}

Constraint grammar was first introduced by \cite{KarlssonTODO}. 
It a tool for disambiguating output by morphological analyser.

\section{Standard implementation(s)}

The first implementation, CG-1, was introduced in \cite{KarlssonTODO}. Karlsson describes the implementation as ``ad hoc`` and ``without any deeper technical contributions to parsing theory``, and adds that ideally, CG should be implemented with finite state methods.
CG-2, implemented by \cite{tapanainen1996}, used finite state technology. 
The latest version, CG-3, was implemented by \cite{TODO} without finite state technology. The implementation introduced new properties, such as ordering of the rules.

\begin{quote}
[--] the Lisp, C, and C++ implementations of the Constraint Grammar Parser are all fairly ad hoc rule interpreters without any deeper technical contributions to parsing theory. These implementations are not based on the use of well understood and theoretically sound parsing algorithms. Rather, they could be characterized as situation-action parsing programs. 
\end{quote}

\subsection{Workflow}

All implementations (TODO check) go through the input many times and apply all possible rules each time. 
After one pass, it may be possible to apply some rules that didn't fire the last time.


\subsection{Resolving conflicts}

For CG-1 and CG-2, ... sections? TODO

In CG-3, the rules are ordered. In case of a conflict, the rule that is described first is given priority.


\section{SAT based implementation}

SAT solving is based on a technique called unit propagation:
a set of complex Boolean clauses is simplified, starting from unit
clauses, which consist of just a single variable, and working up to a solution, where all variables in the set
have a True or False value.

Let us show this with a small example.
We have a set of variables describing properties of people: \texttt{is\_under\_18},
\texttt{has\_driving\_licence} and \texttt{is\_drunk}.

% For instance, the following constraints describe rules for driving a car.
% \begin{verbatim}
% can_drive
% has_driving_licence
% is_under_18
% is_drunk
% \end{verbatim}

% Next, we represent a possible situation in the world. In order to be allowed to drive, a person must have a driving licence and they must not be drunk. This is represented by the clause $can\_drive ∧\wedge has\_driving\_licence ∧\wedge \neg is\_drunk$. Furthermore, from the world knowledge, we know that in order to have a driving licence, one must be over 18. This is represented by the second clause.

Clause 1 describes a possible situation in a world: someone is behaving in away that makes you think of a hypothesis ``either they are underage or
drunk''. This is represented as \texttt{is\_under\_18} $\vee$
\texttt{is\_drunk}. Just by this clause we can't solve the reason for the
behaviour: it can be one of them or both.

Clause 2 comes from the world knowledge that in order to have a
driving licence, one must be over 18. The form of the clause is
obtained by applying negation distributively over the more intuitive
clause $\neg$ (\texttt{has\_driving\_licence} $\wedge$
\texttt{is\_under\_18}): it is not possible to both have driving
licence and be under 18.

\begin{enumerate}
\item \texttt{is\_under\_18} $\vee$ \texttt{is\_drunk}
\item ($\neg$ \texttt{has\_driving\_licence}) $\vee$ ($\neg$ \texttt{is\_under\_18})
\item \texttt{has\_driving\_licence}
\end{enumerate}

Clause 3 provides us some undeniable evidence that
the person has a driving licence. By this clause, 
we know that the variable \texttt{is\_under\_18} is not true.
Knowing that, we can eliminate \texttt{is\_under\_18} from the first
clause. 
The solution is below: the three variables must have these values in order to
satisfy the constraints.

\begin{itemize}
\item \texttt{is\_drunk} = True
\item \texttt{is\_under\_18} = False
\item \texttt{has\_driving\_licence} = True
\end{itemize}

SAT solving is used for many applications where constraints must be
satisfied, such as software and hardware verification.

\subsection{CG formulated in SAT}

We make each analysis a variable. For instance, the fifth line denotes
a hypothesis that the correct analysis of the 3rd item in the sentence
is \texttt{<V,Sg>}. We call this \texttt{Var 5}.

\begin{lstlisting}
((1,[Lem "the",Det]),Var 1)
((2,[Lem "bear",N,Sg]),Var 2)
((2,[Lem "bear",V,Pl]),Var 3)
((3,[Lem "sleep",N,Pl]),Var 4)
((3,[Lem "sleep",V,Sg]),Var 5)
((4,[Lem "in",Prep]),Var 6)
((4,[Lem "in",Adv]),Var 7)
((5,[Lem "the",Det]),Var 8)
((6,[Lem "house",V,Inf]),Var 9)
((6,[Lem "house",N,Sg]),Var 10)
\end{lstlisting}


We have defined our variables, but not yet any truth values. We can
start by doing two things:
\begin{enumerate}
\item Make unambiguous tokens true by default: e.g. \texttt{Var 1}
  shows that the reading \texttt{Det} for the first token must be true.
\item Make hypotheses of possible n-grams. In the example below, we
show bigrams: \texttt{(Var 1 $\wedge$ Var 2) $\vee$ (Var 1 $\wedge$ Var 3)}
means that the first two tokens have analyses \texttt{Det,N} or
\texttt{Det,V}.
\end{enumerate}

We could easily add a third rule: for ambiguous tokens, make sure that
only one reading can be true (or a less strict version, where all
readings can't be true). For instance, \texttt{Not (Var 2 $\wedge$ Var
  3)} would be the constraint that the second token can't be both
\texttt{N} and \texttt{V} at the same time. However,
\cite{KarlssonTODO} argues that CG cannot remove genuine ambiguities;
in a case where a sentence is genuinely ambiguous, all readings are
returned.



\begin{lstlisting}
Var 1
Var 8
(Var 1 :&&: Var 2) :||: (Var 1 :&&: Var 3)
(Var 2 :&&: Var 4) :||: ((Var 2 :&&: Var 5) :||: ((Var 3 :&&: Var 4) :||: (Var 3 :&&: Var 5)))
(Var 4 :&&: Var 6) :||: ((Var 4 :&&: Var 7) :||: ((Var 5 :&&: Var 6) :||: (Var 5 :&&: Var 7)))
(Var 6 :&&: Var 8) :||: (Var 7 :&&: Var 8)
(Var 8 :&&: Var 9) :||: ((Var 8 :&&: Var 10))
\end{lstlisting}
% Not (Var 2 :&&: Var 3)
% Not (Var 4 :&&: Var 5)
% Not (Var 6 :&&: Var 7)
% Not (Var 9 :&&: Var 10)

Another property of CG is that cannot remove all readings: if all
other analyses are eliminated, the remaining analysis must be
returned, even if it were to be eliminated at the next pass. 
However, this property isn't implemented in the SAT version.

\subsection{Data types}

\begin{lstlisting}
data Rule = Remove [Tag] Condition | Select [Tag] Condition

data Condition = C Position [Tag]
               | NOT Condition
               | AND Condition Condition
               | OR Condition Condition 
\end{lstlisting}

The data type for Rule is either remove or select a list of tags, with condition(s).
For Condition, there are basic conditions (position and a list of context tags) and combined conditions, with constructors `NOT', `AND' and `OR'. For instance, the following rule is read as ``remove tag for any verb, if the lemma is \emph{bear} or there is a determiner or an article anywhere to the left''.

\begin{lstlisting}
verb = [V, V2, V3, VV, V2V, VS]
Remove verb (OR (C (Exactly 0)  [Lem "bear"])
                (C (AtLeast -1) [Det,Art])
            )
\end{lstlisting}

There is no special constructor for empty condition (ie. remove/select tag everywhere), but an empty tag list in a condition, i.e. \texttt{C \_ []} is assumed to mean that.

The data type for position can be exact n places or at least n places. The number 0 means the word itself, negative number means \emph{n} positions to the left and positive \emph{n} positions to the right.

\begin{lstlisting}
data Position = Exactly Integer | AtLeast Integer
 \end{lstlisting}

\subsection{Complex conditions}
Conditions constructed by OR are represented as a sequence, and AND as
parallel. In Haskell, I simply use nested lists: everything inside the
outer list is subject to OR, and within the lists AND. This is best
demonstrated by an example:

\begin{itemize}
\item \texttt{OR (OR C1 C2) C3} becomes \texttt{[[C1], [C2], [C3]]} 
\item \texttt{AND (AND C1 C2) C3} becomes \texttt{[[C1, C2, C3]]} 
\item \texttt{AND (OR C1 C2) C3} becomes \texttt{[[C1,C3], [C2,C3]]}
\end{itemize}

\subsection{Conflicts}
If you try to use conflicting rules, you get user error: mzero.

\subsection{Example run}

We show an example run for the sentence \emph{They are both happy and go to the house}. This is
taken from a real output of a morphological analyser, and was
initially ambiguous in the following ways:

\begin{itemize}
\item[] are
\begin{itemize}
\item[] \texttt{<''be'', V, Pres>}
\item[] \texttt{<''are'', N, Sg>}
\end{itemize}

\item[] both
\begin{itemize}
\item[] \texttt{<''both'', CoordConj>}
\item[] \texttt{<''both'',Det>}
\item[] \texttt{<''both'',Pron>}
\end{itemize}


\item[] go
\begin{itemize}
\item[] \texttt{<''go'', V, Inf>}
\item[] \texttt{<''go'', V, Pres>}
\item[] \texttt{<''go'', N, Sg>}
\end{itemize}

\item[] to
\begin{itemize}
\item[] \texttt{<''to'', Prep>}
\item[] \texttt{<''to'', Adv>}
\end{itemize}

\item[] house
\begin{itemize}
\item[] \texttt{<''house'', V, Inf>}
\item[] \texttt{<''house'', V, Pres>}
\item[] \texttt{<''house'', N, Sg>}
\end{itemize}
\end{itemize}

\begin{verbatim}
Tag sequence:
1: [Lem "they",Pron,Subj,Nom,P3]
2: [Lem "are",N,Sg]
3: [Lem "both",Pron]
4: [Lem "happy",Adj]
5: [Lem "and",CoordConj]
6: [Lem "go",V,Inf]
6: [Lem "go",V,Pres]
7: [Lem "to",Prep]
8: [Lem "the",Det]
9: [Lem "house",N,Sg]
\end{verbatim}

%If you want references on a separate page, uncomment the following command.
%\clearpage

%\begin{small}
%\bibliographystyle{plainnat}
%\bibliography{references}
%\end{small}

\end{document}

